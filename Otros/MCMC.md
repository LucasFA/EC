-   <a href="#introducci√≥n" id="toc-introducci√≥n">Introducci√≥n</a>
    -   <a href="#introducci√≥n-a-m√©todos-de-monte-carlo"
        id="toc-introducci√≥n-a-m√©todos-de-monte-carlo">Introducci√≥n a m√©todos de
        Monte Carlo</a>
-   <a href="#cadenas-de-markov-en-m√©todos-de-monte-carlo"
    id="toc-cadenas-de-markov-en-m√©todos-de-monte-carlo">Cadenas de Markov
    en m√©todos de Monte Carlo</a>
    -   <a href="#idea" id="toc-idea">Idea</a>
    -   <a href="#metropolis-hastings"
        id="toc-metropolis-hastings">Metropolis-Hastings</a>
        -   <a href="#desarrollo-formal-de-la-idea"
            id="toc-desarrollo-formal-de-la-idea">Desarrollo formal de la Idea</a>
        -   <a href="#un-ejemplo" id="toc-un-ejemplo">Un ejemplo</a>
-   <a href="#referencias" id="toc-referencias">Referencias</a>

# Introducci√≥n

Vamos a ver qu√© son los M√©todos de Monte Carlo basados en cadenas de
Markov. Las siglas vienen del ingl√©s, *Markov Chain Monte Carlo*. Para
ello, me baso en el tutorial mencionado en las referencias.

En realidad, van a ser procesos de Markov de acuerdo a las definiciones
dadas en clase, (vamos a ver Procesos de Markov con espacio de estados
continuo ‚Ñù y tiempo discreto ‚Ñï) sin embargo seguiremos llam√°ndolo
cadenas de Markov porque aparentemente es la nomenclatura.

Adem√°s, usamos resultados vistos para cadenas de Markov (espacio de
estados numerable) para procesos de Markov, lo cual no vamos a
justificar, pero para lo cual hay referencias online[1].

## Introducci√≥n a m√©todos de Monte Carlo

Los m√©todos de Monte Carlo en general pretenden utilizar muestreo
aleatorio repetidamente para obtener alg√∫n tipo de resultado num√©rico.

Por ejemplo, aqu√≠ incluyo unos scripts de R para aproximar el valor de
la siguiente integral.

‚à´<sub>0</sub><sup>5</sup>sin‚ÄÜ(*x*)*e*<sup>‚àí*x*</sup>*d**x*

    set.seed(1)
    f <- function(x) sin(x) * exp(-x)
    curve(f, 0, 5)

![](MCMC_files/figure-markdown_strict/unnamed-chunk-1-1.png)

Para ello lo que hacemos es tomar un n√∫mero de muestras de una variable
*U*(0,5) del espacio y evaluamos *f* en esos puntos.

    numero_simulaciones <- 1000
    x <- runif(numero_simulaciones, min = 0, max = 5)
    fx <- f(x)

Entonces el valor aproximado de la integral es

    integral_aprox <- (5 - 0) * mean(fx)
    integral_aprox

    ## [1] 0.5105885

Que intuitivamente puedes llegar a reducirlo, a base por altura media.
El valor aproximado por un m√©todo num√©rico cl√°sico ser√≠a

    ## [1] 0.5022749

Adem√°s podemos ver c√≥mo evoluciona la aproximaci√≥n de acuerdo al n√∫mero
de muestras aleatorias tomadas:

![](MCMC_files/figure-markdown_strict/unnamed-chunk-5-1.png) Aqu√≠ adem√°s
hemos indicado en horizontal el valor de la integral calculada
num√©ricamente.

Monte Carlo tambi√©n se puede utilizar para aproximar la probabilidad de
un suceso o, como es m√°s utilizado, para aproximar distribuciones de
probabilidad cuya expresi√≥n anal√≠tica

# Cadenas de Markov en m√©todos de Monte Carlo

Aqu√≠ vamos a abordar el caso de que queramos tomar muestras de una
distribuci√≥n determinada, con motivos de simulaci√≥n, por ejemplo.

## Idea

Lo que vamos a hacer es crear una cadena (de nuevo, en realidad proceso)
de Markov que tenga como distribuci√≥n l√≠mite la distribuci√≥n deseada,
para lo cual debemos exigir que cumpla las condiciones del teorema
erg√≥dico, de forma que la distribuci√≥n l√≠mite sea la estacionaria.

As√≠, vamos a buscar una cadena de Markov irreducible, aperi√≥dica en la
cual todos los estados sean recurrentes positivos.

Claro est√°, esto s√≥lo lo hemos visto para cadenas de Markov (espacio de
estados numerable), pero hay resultados similares en el caso no
numerable. Tambi√©n podemos considerar una cadena de Markov con un n√∫mero
de nodos suficientemente grande, tal que el programa que vamos a ver en
R sea una buena aproximaci√≥n al modelo matem√°tico.

Entonces, dada esta cadena, vamos a caminar por ella, y el estado
resultante de cada paso es una muestra de la distribuci√≥n deseada. Esto
viene de atender al hecho de que esta cadena tiene como distribuci√≥n
l√≠mite la distribuci√≥n de probabilidad deseada.

## Metropolis-Hastings

Sea *f* una funci√≥n proporcional a la funci√≥n de densidad *p* que
deseamos aproximar, con lo cual
$$
    \frac{f(x')}{f(x\_i)} = \frac{p(x')}{p(x\_i)}
$$

Sea *Q*(*x*|*y*) una distribuci√≥n de probabilidad sim√©trica que usaremos
para generar un nuevo candidato dado el punto actual *y*. T√≠picamente se
elige la distribuci√≥n normal (en el n√∫mero de dimensiones adecuado).
Esto es una [caminata aleatoria
gaussiana](https://en.wikipedia.org/wiki/Random_walk#Gaussian_random_walk)

Se toma un estado *x*<sub>*i*</sub> arbitrario.

Entonces el m√©todo consiste en:

1.  Se propone un nuevo estado *x*‚Ä≤ a partir de *x*<sub>*i*</sub> con
    *Q*
2.  Se calcula la probabilidad de aceptaci√≥n del candidato
    *Œ±*‚ÄÑ=‚ÄÑ*m**i**n*{1,‚ÄÜ*f*(*x*‚Ä≤)/*f*(*x*<sub>*i*</sub>)}
3.  Aceptar la nueva posici√≥n con probabilidad *Œ±* (tomando una muestra
    de *U*(0,‚ÄÜ1)).
4.  El siguiente estado *x*<sub>*i*‚ÄÖ+‚ÄÖ1</sub> es o bien el nuevo,
    aceptado, o nos mantenemos en el previo, *x*<sub>*i*</sub>, si fue
    rechazado.

Se obtiene as√≠ una sucesi√≥n {*x*<sub>*n*</sub>}<sub>*n*‚ÄÑ‚àà‚ÄÑ‚Ñï</sub> de
muestras dependientes. Esta dependencia perder√° relevancia para un
n√∫mero suficiente de pasos.

### Desarrollo formal de la Idea

Si esta secci√≥n la completo, posiblemente lo haga dentro de un tiempo.
De momento, la secci√≥n de [derivaci√≥n formal del art√≠culo de Metropolis
Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm#Formal_derivation)
est√° bastante completo.

### Un ejemplo

Tomaremos *X* una variable aleatoria una mixtura[2] de dos
distribuciones normales. Este tipo de distribuci√≥n puede resultar de
tomar muestras de una mezcla heterog√©nea respecto a alguna
caracter√≠stica.

Tomaremos una mixtura de dos normales, una ùí©(‚àí1,0.5) y una ùí©(2,2), con
pesos 0.4 y 0.6‚ÄÑ=‚ÄÑ1‚ÄÖ‚àí‚ÄÖ0.4, respectivamente.

    p <- 0.4
    medias <- c(-1, 2)
    desv_tipicas <- c(.5, 2)
    f <- function(x) {
        p * dnorm(x, medias[1], desv_tipicas[1]) +
            (1 - p) * dnorm(x, medias[2], desv_tipicas[2])
    }
    curve(f(x), col = "red", -4, 8, las = 1)

![](MCMC_files/figure-markdown_strict/unnamed-chunk-6-1.png)

Entonces unas funciones para implementar el m√©todo:

La *Q* que generar√° estados a partir del actual. El valor de la
desviaci√≥n t√≠pica 4 ha sido elegido arbitrariamente.

    q <- function(x) rnorm(n = 1, mean = x, sd = 4)

Esta funci√≥n da un paso del m√©todo anteriormente descrito:

    paso <- function(punto_previo, f, q) {
        ## Nuevo posible punto:
        candidato <- q(punto_previo)
        ## Probabilidad de aceptar el nuevo punto:
        alpha <- min(1, f(candidato) / f(punto_previo))
        ## Aceptarlo con probabilidad alpha
        if (runif(1) < alpha) {
            candidato
        } else { # de lo contrario, quedarse quieto
            punto_previo
        }
    }

Y esta funci√≥n ejecutar√° el m√©todo el n√∫mero de pasos indicado

    m√©todo <- function(x, f, q, npasos) {
        res <- matrix(NA, npasos, length(x))
        for (i in seq_len(npasos)) {
            res[i, ] <- x <- paso(x, f, q)
        }
        drop(res)
    }

Nota: aqu√≠, `m√©todo` est√° implementado de esta extra√±a manera porque
permitir√° generalizar a el caso multidimensional, los cuales son los
interesantes.

Empezando en un punto arbitrario, por ejemplo, 20, y ejecutando 1000
pasos:

    res <- m√©todo(20, f, q, 1000)

![](MCMC_files/figure-markdown_strict/grafica1-1.png)

![](MCMC_files/figure-markdown_strict/grafica2-1.png)

Para *n*‚ÄÑ=‚ÄÑ50000:

![](MCMC_files/figure-markdown_strict/grafica3-1.png)

Aqu√≠ incluyo el c√≥digo para representar las tres √∫ltimas gr√°ficas.

Gr√°fica 1:

    layout(matrix(c(1, 2), 1, 2), widths = c(4, 1))
    par(mar = c(4.1, .5, .5, .5), oma = c(0, 4.1, 0, 0))
    plot(res, type = "s", xpd = NA, ylab = "Parameter", xlab = "Sample", las = 1)
    usr <- par("usr")
    xx <- seq(usr[3], usr[4], length = 301)
    plot(f(xx), xx, type = "l", yaxs = "i", axes = FALSE, xlab = "")

Gr√°fica 2:

    hist(res, 50,
        freq = FALSE, main = "", ylim = c(0, .4), las = 1,
        xlab = "x", ylab = "Probability density"
    )
    z <- integrate(f, -Inf, Inf)$value
    dist_real <- function(x) f(x) / z
    curve(dist_real(x), add = TRUE, col = "red")

Gr√°fica 3:

    set.seed(1)
    res.largo <- m√©todo(20, f, q, 50000)
    hist(res.largo, 100,
        freq = FALSE, main = "", ylim = c(0, .4), las = 1,
        xlab = "x", ylab = "Probability density", col = "grey"
    )
    curve(dist_real(x), add = TRUE, col = "red")

# Referencias

-   Un tutorial en el cual me baso de manera importante:
    -   <https://nicercode.github.io/guides/mcmc/>
-   Wikipedia:
    -   <https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo>
    -   <https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm>
    -   <https://en.wikipedia.org/wiki/Markov_chains_on_a_measurable_state_space>
    -   <https://en.wikipedia.org/wiki/Harris_chain>
-   Bookdown.org
    -   <https://bookdown.org/content/3686/markov-chain-monte-carlo.html>

[1] V√©ase este [art√≠culo sobre lo que llaman cadenas de
Harris](https://en.wikipedia.org/wiki/Harris_chain). Trata procesos de
Markov con espacio de estados no numerables pero medibles.

[2] Una mixtura de una familia de variables aleatorias
{*X*<sub>*i*</sub>}<sub>*i*‚ÄÑ‚àà‚ÄÑ*Œì*</sub> es una variable aleatoria cuya
distribuci√≥n es una combinaci√≥n convexa de las funciones de distribuci√≥n
de las {*X*<sub>*i*</sub>}<sub>*i*‚ÄÑ‚àà‚ÄÑ*Œì*</sub>. Nosotros nos limitaremos
a mixturas finitas, y de hecho veremos s√≥lo la mixtura de dos variables
aleatorias. V√©ase m√°s en [el art√≠culo de
Wikipedia](https://en.wikipedia.org/wiki/Mixture_distribution).
