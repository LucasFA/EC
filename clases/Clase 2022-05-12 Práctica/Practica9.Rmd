---
title: "Práctica 9"
author: "Lucas Fehlau Arbulu"
date: "12-05-2022"
output: 
    html_document:
        toc: true
        number_sections: true
        toc_float: true
---

# Análisis estadístico

```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(fig.cap = "")
rm(list = ls())
```

## Análisis preliminar
Veamos la estructura de 
```{r }
hatco <- read.csv("./inputfiles/hatco2.csv", stringsAsFactors = TRUE)
```

```{r echo= FALSE}
str(hatco)
kable(head(hatco), caption = "Primeros elementos de la tabla")
plot(hatco[, c(6:13)], )
```

## Primera aproximación: Relación lineal
Nos preguntamos sobre la relación lineal entre variables explicativas y explicadas. En algunas variables es significativa

En cuanto a colinealidad, parece significativa entre fidelidad y velocidad, entre velocidad y servconj, y entre servconj y fidelidad
(relación lineal entre los tres)

```{r }
mod1 <- lm(fidelidad ~ velocidad + precio + flexprec + imgfabri + servconj + imgfvent + calidadp, hatco)
mod1
```

### Inferencia sobre el modelo

```{r }
summary(mod1)
```

Observamos que $R^2 = 0.775$, $R^2 \text{ ajustado} = 0.758$

```{r }
anova(mod1)
```

Varias de las variables son estadísticamente no significativas.

Hacemos una observación importante: ANOVA y el sumario del modelo dan resultados distintos en cuanto a la 
importancia de varias variables. Eso sugiere que estén correlacionadas (por lo cual el cambio en una ya se ve reflejada implícitamente en el resto de datos)

## Otro modelo: factores

```{r }
plot(hatco[, c(2:7)])
otroMod <- lm(fidelidad ~ tamano + adquisic + tindustr + tsitcomp + velocidad + precio, hatco)
otroMod
summary(otroMod)
anova(otroMod)
```

El $R^2$ ronda el $80\%$
al nivel de significación $5\%$, todas las variables del mod2 son significativas salvo tindustr (con $p$-valor $0.13 > 0.05$)

## Relevancia del término constante
Recordamos de nuevo:
```{r }
summary(mod1)
```

$p$-valor del término constante: $p = 0.044 < 0.05$. No se rechaza al nivel de significación $5\%$
para el nivel de significación $1\%$ sí se rechaza.
Respectivamente, no podemos prescindir de ninguno de los dos.

```{r }
summary(otroMod)
```

$p$ valor $p < 10^{-16} < 0.01$, no se puede prescindir del término constante ni al Nivel de significación $5\%$ ni $1\%$
────────────────────────────────────────────────────────────────────────────────

## Diagnóstico del modelo
### Homocedasticidad

```{r }
residuos1.estandarizados  <- rstandard(mod1) #' residuos estandarizados
plot(mod1$fitted.values, residuos1.estandarizados)
# plot(xij, residuos1.estandarizados) # TODO:
```

### Incorrelación

```{r }
# plot(hatco$empresa, e)
library(lmtest)
dwtest(mod1)
```

Hipótesis nula: autocorrelación de los errores es 0. No se rechaza

### Normalidad de residuos

```{r }
ks.test(residuos1.estandarizados, pnorm)
qqnorm(residuos1.estandarizados)
qqline(residuos1.estandarizados)
```

### Linealidad

```{r }
library("car")
crPlots(mod1)
```

La mayoría de las variables se ajustan bastante bien a la recta.
Velocidad no tan bien

## Datos anómalos

```{r }
sum(abs(residuos1.estandarizados) > 2.5)
```

2 empresas anómalas, que son:

```{r }
hatco[abs(residuos1.estandarizados) > 2.5, ]
```

### Datos influyentes:

```{r }
cooks.distance(mod1) # leverage, aislamiento
plot(cooks.distance(mod1))
which(cooks.distance(mod1) > 0.1)
```

```{r }
hatvalues(mod1)
plot(hatvalues(mod1))
indices <- which(hatvalues(mod1) > 0.25)
hatco[indices, ]
```

```{r }
influenceIndexPlot(mod1)
```

### Eliminación observaciones anómalas

```{r }
hatco <- hatco[-c(7, 100), ]
mod2 <- lm(fidelidad ~ velocidad + precio + flexprec + imgfabri + servconj + imgfvent + calidadp, hatco)
mod2

summary(mod2)
anova(mod2)
```

Observamos, si comparamos con el sumario y anova del mod1, que ka regresión se ajusta mejor, puesto
que los p-valores son aún más reducidos en varias de las variables: eliminar los datos anómalos hace que nos ajustemos
mejor al modelo
Tampoco es una sorpresa, claro, precisamente hemos eliminado los datos que en cualquier caso son
los que argumentan que el modelo es algo dudoso o no bien ajustado

### Multicolinearidad

```{r }
R <- cor(hatco[, 6:12])
ai <- eigen(R)$values
sqrt(max(ai) / min(ai))
```

VIF:

```{r }
vif(mod2)
```

velocidad, precio y servconj tienen todos un vif > 30

### Selección de variables explicativas

```{r }
step(mod2)
step(mod2, direction = "both")
```

